# DE PROJECT

I am trying to learning Data Engineering from hands-on project. I am following [this bootcamp](https://github.com/DataTalksClub/data-engineering-zoomcamp) and tracking my progress here with some notes.

Each week I will follow the series of [videos](https://www.youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb) and do the homework exercises. 

### GOAL
---
Build the data pipeline as described in the architect diagram below:

<img width="503" alt="arch_2" src="https://user-images.githubusercontent.com/10942817/228657822-7cf485b1-8d76-4a7c-83b9-fd844cb10689.png">

### TOOLS
---
- Google Cloud Platform (GCP): Cloud-based auto-scaling platform by Google
- Google Cloud Storage (GCS): Data Lake
- BigQuery: Data Warehouse
- Terraform: Infrastructure-as-Code (IaC)
- Docker: Containerization
- SQL: Data Analysis & Exploration
- Prefect: Workflow Orchestration
- dbt: Data Transformation
- Spark: Distributed Processing
- Kafka: Streaming

### PROGRESS
---
- WEEK 1 

DOCKER
